This project is about Speech Emotion Recognition (SER) using Machine Learning. The goal is to detect different emotions like happy, sad, angry, neutral, calm, etc., from audio speech. The dataset used is the RAVDESS Emotional Speech Audio dataset from Kaggle, which contains WAV audio files of 24 actors expressing different emotions. The entire project was done using Google Colab, Python, and machine learning libraries.

The process starts by downloading and uploading the dataset ZIP file into Google Colab. After extracting the audio files, MFCC (Mel Frequency Cepstral Coefficients) features are extracted from each WAV file using the librosa library. These features are stored in arrays and used to train multiple machine learning models like SVM, Random Forest, and Logistic Regression. The dataset is split into training and testing sets, and the accuracy is calculated for each model. The SVM model usually performs the best and is selected as the final model. A confusion matrix is also generated to visually show how well the model classified each emotion.

This repository contains the Google Colab notebook named “SER_ML_Model.ipynb,” which includes all the steps from feature extraction to model training and evaluation. The dataset is not included in this repository because audio files are large, but it can be downloaded from Kaggle using the link. Anyone can run this project by opening the notebook in Colab, uploading the dataset ZIP file, and running all the cells. This project shows how speech emotions can be detected using simple machine learning techniques without using deep learning.
